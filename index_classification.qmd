---
title: "Clasificación Binaria con Logistic Regression"
format:
  html:
    toc: true
execute:
  warning: false
  message: false
  echo: true
---

## 1) Carga y exploración inicial

```{python}
import pandas as pd

df = pd.read_csv(
    "data/ensanut_f1_informacion_general.csv",
    sep=";",
    encoding="utf-8-sig",
    quotechar='"',
    escapechar="\\",
    on_bad_lines="skip",
    skipinitialspace=True,
    low_memory=False
)
df = df.rename(columns=lambda c: c.replace("\ufeff", ""))

df.head()
```

```{python}
df.info()
```

```{python}
# Porcentaje de faltantes por columna (top 15)
df.isna().mean().sort_values(ascending=False).head(15)
```

## 2) Selección de variable objetivo (binaria) y EDA breve

> Puedes fijar manualmente la columna objetivo asignando `TARGET = "nombre_columna"`.
> Si lo dejas vacío, se detectará automáticamente la primera columna con exactamente 2 clases.

```{python}
import numpy as np
import matplotlib.pyplot as plt

TARGET = ""  # por ejemplo: "area"

# Detectar objetivo binario si no se especifica
target_col = TARGET.strip() if isinstance(TARGET, str) and TARGET.strip() else None
if target_col is None:
    for c in df.columns:
        nun = df[c].dropna().nunique()
        if nun == 2:
            target_col = c
            break

if target_col is None:
    raise ValueError("No se detectó una columna binaria automáticamente. Define TARGET con el nombre de tu variable objetivo.")

y = df[target_col].astype(str).str.strip()
X = df.drop(columns=[target_col])

# Distribución de clases
vc = y.value_counts(dropna=False)
display(vc)

plt.figure()
vc.plot(kind="bar")
plt.title(f"Distribución de clases - {target_col}")
plt.xlabel("Clase"); plt.ylabel("Frecuencia")
plt.tight_layout(); plt.show()
```

## 3) Normalización de tipos y selección de features

```{python}
import pandas as pd

def to_numeric_if_mostly_numeric(series, threshold=0.9):
    s = series.astype(str)
    # normaliza: quita separador de miles y usa punto decimal
    s_norm = (
        s.str.replace(r"(?<=\d)[\.\s](?=\d{3}\b)", "", regex=True)  # quita . o espacio de miles
         .str.replace(",", ".", regex=False)                             # coma -> punto decimal
    )
    s_num = pd.to_numeric(s_norm, errors="coerce")
    if s_num.notna().mean() >= threshold:
        return s_num
    return series

# Aplica a columnas 'object' y luego recalcula numéricas/categóricas
for c in X.columns:
    if X[c].dtype == object:
        X[c] = to_numeric_if_mostly_numeric(X[c], threshold=0.9)

num_cols = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]
cat_cols = [c for c in X.columns if c not in num_cols]

# Seguridad adicional: fuerza categóricas a string
X[cat_cols] = X[cat_cols].astype(str)

print("Numéricas:", len(num_cols), " | Categóricas:", len(cat_cols))
```

## 4) División Train/Test y Pipeline (imputación, escalado, one-hot) + Modelo

```{python}
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LogisticRegression

# División estratificada
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Numéricas: imputación + escalado
num_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler())
])

# Categóricas: imputación + one-hot (ya forzamos str en X[cat_cols])
cat_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("onehot", OneHotEncoder(handle_unknown="ignore",
                             sparse_output=False,
                             max_categories=50))
])

preprocessor = ColumnTransformer(
    transformers=[
        ("num", num_transformer, num_cols),
        ("cat", cat_transformer, cat_cols)
    ],
    remainder="drop"
)

logreg = LogisticRegression(max_iter=1000, solver="lbfgs")

model = Pipeline(steps=[
    ("prep", preprocessor),
    ("clf", logreg)
])

model.fit(X_train, y_train)
```

## 5) Predicciones y métricas

```{python}
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report

y_pred = model.predict(X_test)

# definir clase positiva como la "mayor" por orden (ajústalo si prefieres otra)
pos_label = sorted(y_test.unique())[-1]

acc  = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred, pos_label=pos_label)
rec  = recall_score(y_test, y_pred, pos_label=pos_label)
f1   = f1_score(y_test, y_pred, pos_label=pos_label)

print("Accuracy :", acc)
print("Precision:", prec)
print("Recall   :", rec)
print("F1       :", f1)

print("\nClassification Report:\n")
print(classification_report(y_test, y_pred))
```

## 6) Matriz de confusión

```{python}
from sklearn.metrics import confusion_matrix
import numpy as np
import matplotlib.pyplot as plt

labels = sorted(y_test.unique())
cm = confusion_matrix(y_test, y_pred, labels=labels)

fig, ax = plt.subplots()
im = ax.imshow(cm, cmap="Blues")
ax.set_title("Matriz de confusión")
ax.set_xlabel("Predicha"); ax.set_ylabel("Real")
ax.set_xticks(range(len(labels))); ax.set_xticklabels(labels)
ax.set_yticks(range(len(labels))); ax.set_yticklabels(labels)
for i in range(cm.shape[0]):
    for j in range(cm.shape[1]):
        ax.text(j, i, cm[i, j], ha="center", va="center")
fig.colorbar(im)
plt.tight_layout(); plt.show()
```

## 7) Curva ROC y AUC

```{python}
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

if len(labels) == 2:
    pos_label = sorted(y_train.unique())[-1]
    y_proba = model.predict_proba(X_test)[:, list(model.classes_).index(pos_label)]

    fpr, tpr, thr = roc_curve(y_test, y_proba, pos_label=pos_label)
    roc_auc = auc(fpr, tpr)

    plt.figure()
    plt.plot(fpr, tpr, label=f"ROC (AUC = {roc_auc:.3f})")
    plt.plot([0,1],[0,1], "--")
    plt.xlabel("False Positive Rate"); plt.ylabel("True Positive Rate")
    plt.title("Curva ROC"); plt.legend()
    plt.tight_layout(); plt.show()

    print("AUC:", roc_auc)
else:
    print("ROC/AUC solo aplica a problemas estrictamente binarios (2 clases).")
```

## 8) Comentarios finales

- **Normalización de tipos**: convertir texto numérico a número y forzar categóricas a string evita el error `['float','str']` en `OneHotEncoder`.
- **Pipeline** asegura reproducibilidad (imputación/escalado/one-hot + modelo).
- Si las métricas no son satisfactorias: prueba `class_weight='balanced'`, ajustar `C` en `LogisticRegression`, selección/ingeniería de features o modelos alternativos.
