---
title: "Clasificación Binaria con Logistic Regression"
format:
  html:
    toc: true
execute:
  warning: false
  message: false
  echo: true
---

## 1) Carga y exploración inicial

```{python}
import pandas as pd

path = "data/ensanut_f1_informacion_general.csv"

df = pd.read_csv(
    path,
    sep=None,                # autodetecta delimitador
    engine="python",         # necesario para sep=None
    encoding="latin1",       # o "utf-8"/"cp1252" si aplica
    on_bad_lines="skip",     # si hay filas mal formadas, sáltalas
    skipinitialspace=True    # ignora espacios después del separador
)

df.head()

```

```{python}
df.info()
```

```{python}
# Porcentaje de faltantes por columna (top 15)
df.isna().mean().sort_values(ascending=False).head(15)
```

## 2) Selección de variable objetivo (binaria) y EDA breve

> Puedes fijar manualmente la columna objetivo asignando `TARGET = "nombre_columna"`.
> Si lo dejas vacío, el notebook intentará **detectar** la primera columna categórica binaria.

```{python}
import numpy as np

TARGET = ""  # <- opcional: pon aquí tu columna binaria (str). Si la dejas en "", se detecta automáticamente.

# Detectar objetivo binario si no se especifica
target_col = TARGET.strip() if isinstance(TARGET, str) and TARGET.strip() else None
if target_col is None:
    # candidata: columna con exactamente 2 valores distintos (ignorando NaN)
    for c in df.columns:
        nun = df[c].dropna().nunique()
        if nun == 2:
            target_col = c
            break

if target_col is None:
    raise ValueError("No se detectó una columna binaria automáticamente. Define TARGET con el nombre de tu variable objetivo.")

# Asegurar que el objetivo sea categórico (0/1 o etiquetas)
y_raw = df[target_col]

# Mostrar distribución de clases
y_raw.value_counts(dropna=False)
```

```{python}
import matplotlib.pyplot as plt

vc = y_raw.value_counts()
plt.figure()
vc.plot(kind="bar")
plt.title(f"Distribución de clases - {target_col}")
plt.xlabel("Clase")
plt.ylabel("Frecuencia")
plt.tight_layout()
plt.show()
```

## 3) División Train/Test y preparación de datos

```{python}
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer

# Separar X e y
X = df.drop(columns=[target_col])
y = y_raw

# Detectar tipos
num_cols = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]
cat_cols = [c for c in X.columns if c not in num_cols]

len(num_cols), len(cat_cols)
```

```{python}
# División estratificada para mantener la proporción de clases
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Transformaciones: imputación + escalado para numéricas; imputación + OneHot para categóricas
num_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler())
])

# Para scikit-learn >= 1.2: usar sparse_output=False
cat_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("onehot", OneHotEncoder(handle_unknown="ignore", sparse_output=False, max_categories=50))
])

preprocessor = ColumnTransformer(transformers=[
    ("num", num_transformer, num_cols),
    ("cat", cat_transformer, cat_cols)
])
```

## 4) Modelo: Logistic Regression (Pipeline) y entrenamiento

```{python}
from sklearn.linear_model import LogisticRegression

# Modelo base (ajustable)
logreg = LogisticRegression(max_iter=1000, solver="lbfgs")

model = Pipeline(steps=[
    ("prep", preprocessor),
    ("clf", logreg)
])

model.fit(X_train, y_train)
```

## 5) Predicciones y métricas

```{python}
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report

y_pred = model.predict(X_test)

# definir clase positiva como la "mayor" por orden (ajústalo si prefieres otra)
pos_label = sorted(y_test.unique())[-1]

acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred, pos_label=pos_label)
rec = recall_score(y_test, y_pred, pos_label=pos_label)
f1 = f1_score(y_test, y_pred, pos_label=pos_label)

acc, prec, rec, f1
```

```{python}
print(classification_report(y_test, y_pred))
```

## 6) Matriz de confusión (visualización)

```{python}
from sklearn.metrics import confusion_matrix
import numpy as np
import matplotlib.pyplot as plt

labels = sorted(y_test.unique())
cm = confusion_matrix(y_test, y_pred, labels=labels)

fig, ax = plt.subplots(figsize=(4.5,4))
im = ax.imshow(cm, cmap="Blues")
ax.set_title("Matriz de confusión")
ax.set_xlabel("Predicha")
ax.set_ylabel("Real")
ax.set_xticks(range(len(labels))); ax.set_xticklabels(labels, rotation=0)
ax.set_yticks(range(len(labels))); ax.set_yticklabels(labels)
for i in range(cm.shape[0]):
    for j in range(cm.shape[1]):
        ax.text(j, i, cm[i, j], ha="center", va="center")
fig.colorbar(im)
plt.tight_layout()
plt.show()
```

## 7) Curva ROC y AUC

```{python}
from sklearn.metrics import roc_curve, auc

pos_label = sorted(y_train.unique())[-1]
y_proba = model.predict_proba(X_test)[:, list(model.classes_).index(pos_label)]

fpr, tpr, thr = roc_curve(y_test, y_proba, pos_label=pos_label)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(5,4))
plt.plot(fpr, tpr, label=f"ROC (AUC = {roc_auc:.3f})")
plt.plot([0,1],[0,1], "--", alpha=0.6)
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("Curva ROC")
plt.legend()
plt.tight_layout()
plt.show()

roc_auc
```

## 8) Discusión de resultados

- **Accuracy / Precision / Recall / F1**: interpreta cada métrica según el costo de errores.
- **Matriz de confusión**: identifica dónde se equivoca más el modelo.
- **ROC/AUC**: valores cercanos a 1 indican mejor discriminación; ~0.5 es aleatorio.
- Si el desempeño es bajo: prueba `class_weight='balanced'`, regularización (ajustar `C`), ingeniería de variables o modelos alternativos (árboles, ensambles).
