[
  {
    "objectID": "index_classification.html",
    "href": "index_classification.html",
    "title": "Clasificación Binaria con Logistic Regression",
    "section": "",
    "text": "import pandas as pd\n\npath = \"data/ensanut_f1_informacion_general.csv\"\n\ndef load_csv_robust(path):\n    tries = [\n        dict(sep=None, engine=\"python\", encoding=\"latin1\"),          # autodetecta\n        dict(sep=\";\", encoding=\"latin1\", quotechar='\"', escapechar=\"\\\\\"),\n        dict(sep=\",\", encoding=\"latin1\", quotechar='\"', escapechar=\"\\\\\"),\n        dict(sep=\"\\t\", encoding=\"latin1\"),\n    ]\n    last = None\n    for kw in tries:\n        try:\n            df = pd.read_csv(\n                path,\n                on_bad_lines=\"skip\",       # salta filas mal formadas\n                skipinitialspace=True,     # ignora espacios tras el separador\n                **kw\n            )\n            # Heurística simple: al menos 2 columnas válidas\n            if df.shape[1] &gt;= 2:\n                return df, kw\n        except Exception as e:\n            last = e\n    raise last\n\ndf, used_kwargs = load_csv_robust(path)\nprint(\"Opciones usadas:\", used_kwargs)\ndf.head()\n\nOpciones usadas: {'sep': None, 'engine': 'python', 'encoding': 'latin1'}\n\n\n\n\n\n\n\n\n\nï»¿area\nciudad\nzona\nsector\nvivienda\nhogar\nnciudad\nregional\nvo\ntothog\n...\nif9a\nif9b\nif10\nnf12\nn1_flebo\nn2_flebo\nidhog\nidviv\nidsector\npw\n\n\n\n\n0\nurbano\ncuenca\n1\n1\n1\n1\nCUENCA\nsur\n4\n1\n...\nsi\n2.0\n4.0\n2.0\n4402.0\n4402.0\n10150001001011\n1015000100101\n10150001001\n274,240540540541\n\n\n1\nurbano\ncuenca\n1\n1\n2\n1\nCUENCA\nsur\n11\n1\n...\nno\nNaN\n2.0\n0.0\nNaN\nNaN\n10150001001021\n1015000100102\n10150001001\n274,240540540541\n\n\n2\nurbano\ncuenca\n1\n1\n3\n1\nCUENCA\nsur\n12\n1\n...\nsi\n1.0\n3.0\n2.0\n4202.0\n4202.0\n10150001001031\n1015000100103\n10150001001\n274,240540540541\n\n\n3\nurbano\ncuenca\n1\n1\n5\n1\nCUENCA\nsur\n7\n1\n...\nsi\n1.0\n3.0\n1.0\n4401.0\n4401.0\n10150001001051\n1015000100105\n10150001001\n274,240540540541\n\n\n4\nurbano\ncuenca\n1\n1\n6\n1\nCUENCA\nsur\n8\n1\n...\nno\nNaN\n1.0\n0.0\nNaN\nNaN\n10150001001061\n1015000100106\n10150001001\n274,240540540541\n\n\n\n\n5 rows × 59 columns\n\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 23265 entries, 0 to 23264\nData columns (total 59 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   ï»¿area   23265 non-null  object \n 1   ciudad    23265 non-null  object \n 2   zona      23265 non-null  int64  \n 3   sector    23265 non-null  int64  \n 4   vivienda  23265 non-null  int64  \n 5   hogar     23265 non-null  int64  \n 6   nciudad   23265 non-null  object \n 7   regional  23232 non-null  object \n 8   vo        23265 non-null  int64  \n 9   tothog    23265 non-null  int64  \n 10  altitud   23265 non-null  object \n 11  resultad  23265 non-null  object \n 12  informa   19954 non-null  object \n 13  parentes  19954 non-null  object \n 14  codsup    23265 non-null  object \n 15  codenc    23265 non-null  object \n 16  codcod    23265 non-null  object \n 17  coddig    23265 non-null  int64  \n 18  supere1   23265 non-null  object \n 19  supere2   23265 non-null  object \n 20  supere3   23265 non-null  object \n 21  superr1   23265 non-null  object \n 22  superr2   23265 non-null  object \n 23  superr3   23265 non-null  object \n 24  supern1   23265 non-null  object \n 25  supern2   23265 non-null  object \n 26  supern3   23265 non-null  object \n 27  dia       23265 non-null  object \n 28  mes       23265 non-null  object \n 29  anio      23265 non-null  object \n 30  numpers   19949 non-null  float64\n 31  mi00a     19949 non-null  object \n 32  mi00b     295 non-null    float64\n 33  mo00a     19949 non-null  object \n 34  mo00b     308 non-null    float64\n 35  if2       19949 non-null  object \n 36  if3a      19949 non-null  object \n 37  if3b      5831 non-null   float64\n 38  if4a      19949 non-null  object \n 39  if4b      8205 non-null   float64\n 40  if4o      8205 non-null   float64\n 41  if5a      19949 non-null  object \n 42  if5b      8073 non-null   float64\n 43  if6a      19949 non-null  object \n 44  if6b      10606 non-null  float64\n 45  if7a      19949 non-null  object \n 46  if7b      19154 non-null  float64\n 47  if8a      19949 non-null  object \n 48  if8b      11937 non-null  float64\n 49  if9a      19949 non-null  object \n 50  if9b      13839 non-null  float64\n 51  if10      19949 non-null  float64\n 52  nf12      19949 non-null  float64\n 53  n1_flebo  10019 non-null  float64\n 54  n2_flebo  10019 non-null  float64\n 55  idhog     23265 non-null  int64  \n 56  idviv     23265 non-null  int64  \n 57  idsector  23265 non-null  int64  \n 58  pw        19949 non-null  object \ndtypes: float64(15), int64(10), object(34)\nmemory usage: 10.5+ MB\n\n\n\n# Porcentaje de faltantes por columna (top 15)\ndf.isna().mean().sort_values(ascending=False).head(15)\n\nmi00b       0.987320\nmo00b       0.986761\nif3b        0.749366\nif5b        0.652998\nif4o        0.647324\nif4b        0.647324\nn2_flebo    0.569353\nn1_flebo    0.569353\nif6b        0.544122\nif8b        0.486912\nif9b        0.405158\nif7b        0.176703\nnumpers     0.142532\nif3a        0.142532\nif4a        0.142532\ndtype: float64"
  },
  {
    "objectID": "index_classification.html#carga-y-exploración-inicial",
    "href": "index_classification.html#carga-y-exploración-inicial",
    "title": "Clasificación Binaria con Logistic Regression",
    "section": "",
    "text": "import pandas as pd\n\npath = \"data/ensanut_f1_informacion_general.csv\"\n\ndef load_csv_robust(path):\n    tries = [\n        dict(sep=None, engine=\"python\", encoding=\"latin1\"),          # autodetecta\n        dict(sep=\";\", encoding=\"latin1\", quotechar='\"', escapechar=\"\\\\\"),\n        dict(sep=\",\", encoding=\"latin1\", quotechar='\"', escapechar=\"\\\\\"),\n        dict(sep=\"\\t\", encoding=\"latin1\"),\n    ]\n    last = None\n    for kw in tries:\n        try:\n            df = pd.read_csv(\n                path,\n                on_bad_lines=\"skip\",       # salta filas mal formadas\n                skipinitialspace=True,     # ignora espacios tras el separador\n                **kw\n            )\n            # Heurística simple: al menos 2 columnas válidas\n            if df.shape[1] &gt;= 2:\n                return df, kw\n        except Exception as e:\n            last = e\n    raise last\n\ndf, used_kwargs = load_csv_robust(path)\nprint(\"Opciones usadas:\", used_kwargs)\ndf.head()\n\nOpciones usadas: {'sep': None, 'engine': 'python', 'encoding': 'latin1'}\n\n\n\n\n\n\n\n\n\nï»¿area\nciudad\nzona\nsector\nvivienda\nhogar\nnciudad\nregional\nvo\ntothog\n...\nif9a\nif9b\nif10\nnf12\nn1_flebo\nn2_flebo\nidhog\nidviv\nidsector\npw\n\n\n\n\n0\nurbano\ncuenca\n1\n1\n1\n1\nCUENCA\nsur\n4\n1\n...\nsi\n2.0\n4.0\n2.0\n4402.0\n4402.0\n10150001001011\n1015000100101\n10150001001\n274,240540540541\n\n\n1\nurbano\ncuenca\n1\n1\n2\n1\nCUENCA\nsur\n11\n1\n...\nno\nNaN\n2.0\n0.0\nNaN\nNaN\n10150001001021\n1015000100102\n10150001001\n274,240540540541\n\n\n2\nurbano\ncuenca\n1\n1\n3\n1\nCUENCA\nsur\n12\n1\n...\nsi\n1.0\n3.0\n2.0\n4202.0\n4202.0\n10150001001031\n1015000100103\n10150001001\n274,240540540541\n\n\n3\nurbano\ncuenca\n1\n1\n5\n1\nCUENCA\nsur\n7\n1\n...\nsi\n1.0\n3.0\n1.0\n4401.0\n4401.0\n10150001001051\n1015000100105\n10150001001\n274,240540540541\n\n\n4\nurbano\ncuenca\n1\n1\n6\n1\nCUENCA\nsur\n8\n1\n...\nno\nNaN\n1.0\n0.0\nNaN\nNaN\n10150001001061\n1015000100106\n10150001001\n274,240540540541\n\n\n\n\n5 rows × 59 columns\n\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 23265 entries, 0 to 23264\nData columns (total 59 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   ï»¿area   23265 non-null  object \n 1   ciudad    23265 non-null  object \n 2   zona      23265 non-null  int64  \n 3   sector    23265 non-null  int64  \n 4   vivienda  23265 non-null  int64  \n 5   hogar     23265 non-null  int64  \n 6   nciudad   23265 non-null  object \n 7   regional  23232 non-null  object \n 8   vo        23265 non-null  int64  \n 9   tothog    23265 non-null  int64  \n 10  altitud   23265 non-null  object \n 11  resultad  23265 non-null  object \n 12  informa   19954 non-null  object \n 13  parentes  19954 non-null  object \n 14  codsup    23265 non-null  object \n 15  codenc    23265 non-null  object \n 16  codcod    23265 non-null  object \n 17  coddig    23265 non-null  int64  \n 18  supere1   23265 non-null  object \n 19  supere2   23265 non-null  object \n 20  supere3   23265 non-null  object \n 21  superr1   23265 non-null  object \n 22  superr2   23265 non-null  object \n 23  superr3   23265 non-null  object \n 24  supern1   23265 non-null  object \n 25  supern2   23265 non-null  object \n 26  supern3   23265 non-null  object \n 27  dia       23265 non-null  object \n 28  mes       23265 non-null  object \n 29  anio      23265 non-null  object \n 30  numpers   19949 non-null  float64\n 31  mi00a     19949 non-null  object \n 32  mi00b     295 non-null    float64\n 33  mo00a     19949 non-null  object \n 34  mo00b     308 non-null    float64\n 35  if2       19949 non-null  object \n 36  if3a      19949 non-null  object \n 37  if3b      5831 non-null   float64\n 38  if4a      19949 non-null  object \n 39  if4b      8205 non-null   float64\n 40  if4o      8205 non-null   float64\n 41  if5a      19949 non-null  object \n 42  if5b      8073 non-null   float64\n 43  if6a      19949 non-null  object \n 44  if6b      10606 non-null  float64\n 45  if7a      19949 non-null  object \n 46  if7b      19154 non-null  float64\n 47  if8a      19949 non-null  object \n 48  if8b      11937 non-null  float64\n 49  if9a      19949 non-null  object \n 50  if9b      13839 non-null  float64\n 51  if10      19949 non-null  float64\n 52  nf12      19949 non-null  float64\n 53  n1_flebo  10019 non-null  float64\n 54  n2_flebo  10019 non-null  float64\n 55  idhog     23265 non-null  int64  \n 56  idviv     23265 non-null  int64  \n 57  idsector  23265 non-null  int64  \n 58  pw        19949 non-null  object \ndtypes: float64(15), int64(10), object(34)\nmemory usage: 10.5+ MB\n\n\n\n# Porcentaje de faltantes por columna (top 15)\ndf.isna().mean().sort_values(ascending=False).head(15)\n\nmi00b       0.987320\nmo00b       0.986761\nif3b        0.749366\nif5b        0.652998\nif4o        0.647324\nif4b        0.647324\nn2_flebo    0.569353\nn1_flebo    0.569353\nif6b        0.544122\nif8b        0.486912\nif9b        0.405158\nif7b        0.176703\nnumpers     0.142532\nif3a        0.142532\nif4a        0.142532\ndtype: float64"
  },
  {
    "objectID": "index_classification.html#selección-de-variable-objetivo-binaria-y-eda-breve",
    "href": "index_classification.html#selección-de-variable-objetivo-binaria-y-eda-breve",
    "title": "Clasificación Binaria con Logistic Regression",
    "section": "2) Selección de variable objetivo (binaria) y EDA breve",
    "text": "2) Selección de variable objetivo (binaria) y EDA breve\n\nPuedes fijar manualmente la columna objetivo asignando TARGET = \"nombre_columna\". Si lo dejas vacío, el notebook intentará detectar la primera columna categórica binaria.\n\n\nimport numpy as np\n\nTARGET = \"\"  # &lt;- opcional: pon aquí tu columna binaria (str). Si la dejas en \"\", se detecta automáticamente.\n\n# Detectar objetivo binario si no se especifica\ntarget_col = TARGET.strip() if isinstance(TARGET, str) and TARGET.strip() else None\nif target_col is None:\n    # candidata: columna con exactamente 2 valores distintos (ignorando NaN)\n    for c in df.columns:\n        nun = df[c].dropna().nunique()\n        if nun == 2:\n            target_col = c\n            break\n\nif target_col is None:\n    raise ValueError(\"No se detectó una columna binaria automáticamente. Define TARGET con el nombre de tu variable objetivo.\")\n\n# Asegurar que el objetivo sea categórico (0/1 o etiquetas)\ny_raw = df[target_col]\n\n# Mostrar distribución de clases\ny_raw.value_counts(dropna=False)\n\nï»¿area\nurbano    14122\nrural      9143\nName: count, dtype: int64\n\n\n\nimport matplotlib.pyplot as plt\n\nvc = y_raw.value_counts()\nplt.figure()\nvc.plot(kind=\"bar\")\nplt.title(f\"Distribución de clases - {target_col}\")\nplt.xlabel(\"Clase\")\nplt.ylabel(\"Frecuencia\")\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "index_classification.html#división-traintest-y-preparación-de-datos",
    "href": "index_classification.html#división-traintest-y-preparación-de-datos",
    "title": "Clasificación Binaria con Logistic Regression",
    "section": "3) División Train/Test y preparación de datos",
    "text": "3) División Train/Test y preparación de datos\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.impute import SimpleImputer\n\n# Separar X e y\nX = df.drop(columns=[target_col])\ny = y_raw\n\n# Detectar tipos\nnum_cols = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]\ncat_cols = [c for c in X.columns if c not in num_cols]\n\nlen(num_cols), len(cat_cols)\n\n(25, 33)\n\n\n\n# División estratificada para mantener la proporción de clases\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\n# Transformaciones: imputación + escalado para numéricas; imputación + OneHot para categóricas\nnum_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"median\")),\n    (\"scaler\", StandardScaler())\n])\n\n# Para scikit-learn &gt;= 1.2: usar sparse_output=False\ncat_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, max_categories=50))\n])\n\npreprocessor = ColumnTransformer(transformers=[\n    (\"num\", num_transformer, num_cols),\n    (\"cat\", cat_transformer, cat_cols)\n])"
  },
  {
    "objectID": "index_classification.html#modelo-logistic-regression-pipeline-y-entrenamiento",
    "href": "index_classification.html#modelo-logistic-regression-pipeline-y-entrenamiento",
    "title": "Clasificación Binaria con Logistic Regression",
    "section": "4) Modelo: Logistic Regression (Pipeline) y entrenamiento",
    "text": "4) Modelo: Logistic Regression (Pipeline) y entrenamiento\n\nfrom sklearn.linear_model import LogisticRegression\n\n# Modelo base (ajustable)\nlogreg = LogisticRegression(max_iter=1000, solver=\"lbfgs\")\n\nmodel = Pipeline(steps=[\n    (\"prep\", preprocessor),\n    (\"clf\", logreg)\n])\n\nmodel.fit(X_train, y_train)\n\nPipeline(steps=[('prep',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  ['zona', 'sector', 'vivienda',\n                                                   'hogar', 'vo', 'tothog',\n                                                   'coddig', 'numpers', 'mi00b',\n                                                   'mo00b', 'if3b', 'if4b',\n                                                   'if4o', 'if5b', 'if6b',\n                                                   'if7b', 'if8b', 'if9b',\n                                                   'if10', 'nf12', 'n1_flebo',\n                                                   'n2_flebo', 'idhog', 'idviv',\n                                                   'id...\n                                                                                 max_categories=50,\n                                                                                 sparse_output=False))]),\n                                                  ['ciudad', 'nciudad',\n                                                   'regional', 'altitud',\n                                                   'resultad', 'informa',\n                                                   'parentes', 'codsup',\n                                                   'codenc', 'codcod',\n                                                   'supere1', 'supere2',\n                                                   'supere3', 'superr1',\n                                                   'superr2', 'superr3',\n                                                   'supern1', 'supern2',\n                                                   'supern3', 'dia', 'mes',\n                                                   'anio', 'mi00a', 'mo00a',\n                                                   'if2', 'if3a', 'if4a',\n                                                   'if5a', 'if6a', 'if7a', ...])])),\n                ('clf', LogisticRegression(max_iter=1000))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.Pipeline?Documentation for PipelineiFitted\n        \n            \n                Parameters\n                \n\n\n\n\nsteps \n[('prep', ...), ('clf', ...)]\n\n\n\ntransform_input \nNone\n\n\n\nmemory \nNone\n\n\n\nverbose \nFalse\n\n\n\n\n            \n        \n    prep: ColumnTransformer?Documentation for prep: ColumnTransformer\n        \n            \n                Parameters\n                \n\n\n\n\ntransformers \n[('num', ...), ('cat', ...)]\n\n\n\nremainder \n'drop'\n\n\n\nsparse_threshold \n0.3\n\n\n\nn_jobs \nNone\n\n\n\ntransformer_weights \nNone\n\n\n\nverbose \nFalse\n\n\n\nverbose_feature_names_out \nTrue\n\n\n\nforce_int_remainder_cols \n'deprecated'\n\n\n\n\n            \n        \n    num['zona', 'sector', 'vivienda', 'hogar', 'vo', 'tothog', 'coddig', 'numpers', 'mi00b', 'mo00b', 'if3b', 'if4b', 'if4o', 'if5b', 'if6b', 'if7b', 'if8b', 'if9b', 'if10', 'nf12', 'n1_flebo', 'n2_flebo', 'idhog', 'idviv', 'idsector']SimpleImputer?Documentation for SimpleImputer\n        \n            \n                Parameters\n                \n\n\n\n\nmissing_values \nnan\n\n\n\nstrategy \n'median'\n\n\n\nfill_value \nNone\n\n\n\ncopy \nTrue\n\n\n\nadd_indicator \nFalse\n\n\n\nkeep_empty_features \nFalse\n\n\n\n\n            \n        \n    StandardScaler?Documentation for StandardScaler\n        \n            \n                Parameters\n                \n\n\n\n\ncopy \nTrue\n\n\n\nwith_mean \nTrue\n\n\n\nwith_std \nTrue\n\n\n\n\n            \n        \n    cat['ciudad', 'nciudad', 'regional', 'altitud', 'resultad', 'informa', 'parentes', 'codsup', 'codenc', 'codcod', 'supere1', 'supere2', 'supere3', 'superr1', 'superr2', 'superr3', 'supern1', 'supern2', 'supern3', 'dia', 'mes', 'anio', 'mi00a', 'mo00a', 'if2', 'if3a', 'if4a', 'if5a', 'if6a', 'if7a', 'if8a', 'if9a', 'pw']SimpleImputer?Documentation for SimpleImputer\n        \n            \n                Parameters\n                \n\n\n\n\nmissing_values \nnan\n\n\n\nstrategy \n'most_frequent'\n\n\n\nfill_value \nNone\n\n\n\ncopy \nTrue\n\n\n\nadd_indicator \nFalse\n\n\n\nkeep_empty_features \nFalse\n\n\n\n\n            \n        \n    OneHotEncoder?Documentation for OneHotEncoder\n        \n            \n                Parameters\n                \n\n\n\n\ncategories \n'auto'\n\n\n\ndrop \nNone\n\n\n\nsparse_output \nFalse\n\n\n\ndtype \n&lt;class 'numpy.float64'&gt;\n\n\n\nhandle_unknown \n'ignore'\n\n\n\nmin_frequency \nNone\n\n\n\nmax_categories \n50\n\n\n\nfeature_name_combiner \n'concat'\n\n\n\n\n            \n        \n    LogisticRegression?Documentation for LogisticRegression\n        \n            \n                Parameters\n                \n\n\n\n\npenalty \n'l2'\n\n\n\ndual \nFalse\n\n\n\ntol \n0.0001\n\n\n\nC \n1.0\n\n\n\nfit_intercept \nTrue\n\n\n\nintercept_scaling \n1\n\n\n\nclass_weight \nNone\n\n\n\nrandom_state \nNone\n\n\n\nsolver \n'lbfgs'\n\n\n\nmax_iter \n1000\n\n\n\nmulti_class \n'deprecated'\n\n\n\nverbose \n0\n\n\n\nwarm_start \nFalse\n\n\n\nn_jobs \nNone\n\n\n\nl1_ratio \nNone"
  },
  {
    "objectID": "index_classification.html#predicciones-y-métricas",
    "href": "index_classification.html#predicciones-y-métricas",
    "title": "Clasificación Binaria con Logistic Regression",
    "section": "5) Predicciones y métricas",
    "text": "5) Predicciones y métricas\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n\ny_pred = model.predict(X_test)\n\n# definir clase positiva como la \"mayor\" por orden (ajústalo si prefieres otra)\npos_label = sorted(y_test.unique())[-1]\n\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred, pos_label=pos_label)\nrec = recall_score(y_test, y_pred, pos_label=pos_label)\nf1 = f1_score(y_test, y_pred, pos_label=pos_label)\n\nacc, prec, rec, f1\n\n(0.98989898989899, 0.9890806622050018, 0.9943342776203966, 0.9917005120960621)\n\n\n\nprint(classification_report(y_test, y_pred))\n\n              precision    recall  f1-score   support\n\n       rural       0.99      0.98      0.99      1829\n      urbano       0.99      0.99      0.99      2824\n\n    accuracy                           0.99      4653\n   macro avg       0.99      0.99      0.99      4653\nweighted avg       0.99      0.99      0.99      4653"
  },
  {
    "objectID": "index_classification.html#matriz-de-confusión-visualización",
    "href": "index_classification.html#matriz-de-confusión-visualización",
    "title": "Clasificación Binaria con Logistic Regression",
    "section": "6) Matriz de confusión (visualización)",
    "text": "6) Matriz de confusión (visualización)\n\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nlabels = sorted(y_test.unique())\ncm = confusion_matrix(y_test, y_pred, labels=labels)\n\nfig, ax = plt.subplots(figsize=(4.5,4))\nim = ax.imshow(cm, cmap=\"Blues\")\nax.set_title(\"Matriz de confusión\")\nax.set_xlabel(\"Predicha\")\nax.set_ylabel(\"Real\")\nax.set_xticks(range(len(labels))); ax.set_xticklabels(labels, rotation=0)\nax.set_yticks(range(len(labels))); ax.set_yticklabels(labels)\nfor i in range(cm.shape[0]):\n    for j in range(cm.shape[1]):\n        ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\nfig.colorbar(im)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "index_classification.html#curva-roc-y-auc",
    "href": "index_classification.html#curva-roc-y-auc",
    "title": "Clasificación Binaria con Logistic Regression",
    "section": "7) Curva ROC y AUC",
    "text": "7) Curva ROC y AUC\n\nfrom sklearn.metrics import roc_curve, auc\n\npos_label = sorted(y_train.unique())[-1]\ny_proba = model.predict_proba(X_test)[:, list(model.classes_).index(pos_label)]\n\nfpr, tpr, thr = roc_curve(y_test, y_proba, pos_label=pos_label)\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(5,4))\nplt.plot(fpr, tpr, label=f\"ROC (AUC = {roc_auc:.3f})\")\nplt.plot([0,1],[0,1], \"--\", alpha=0.6)\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"Curva ROC\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\nroc_auc\n\n\n\n\n\n\n\n\n0.9995856804984844"
  },
  {
    "objectID": "index_classification.html#discusión-de-resultados",
    "href": "index_classification.html#discusión-de-resultados",
    "title": "Clasificación Binaria con Logistic Regression",
    "section": "8) Discusión de resultados",
    "text": "8) Discusión de resultados\n\nAccuracy / Precision / Recall / F1: interpreta cada métrica según el costo de errores.\nMatriz de confusión: identifica dónde se equivoca más el modelo.\nROC/AUC: valores cercanos a 1 indican mejor discriminación; ~0.5 es aleatorio.\nSi el desempeño es bajo: prueba class_weight='balanced', regularización (ajustar C), ingeniería de variables o modelos alternativos (árboles, ensambles)."
  },
  {
    "objectID": "index.html#reales-vs-predichos",
    "href": "index.html#reales-vs-predichos",
    "title": "Midterm",
    "section": "Reales vs Predichos",
    "text": "Reales vs Predichos\n\nplt.figure()\nplt.scatter(y_test, y_pred, alpha=0.4)\nlims = [min(y_test.min(), y_pred.min()), max(y_test.max(), y_pred.max())]\nplt.plot(lims, lims)\nplt.xlabel(\"Real\"); plt.ylabel(\"Predicho\")\nplt.title(\"Valores reales vs. predichos\")\nplt.show()"
  },
  {
    "objectID": "index.html#curva-de-aprendizaje-muestra",
    "href": "index.html#curva-de-aprendizaje-muestra",
    "title": "Midterm",
    "section": "Curva de aprendizaje (muestra)",
    "text": "Curva de aprendizaje (muestra)\n\nfrom sklearn.model_selection import learning_curve\n\nsample_size = min(10000, len(X))\nX_sample = X.sample(sample_size, random_state=42)\ny_sample = y.loc[X_sample.index]\n\ntrain_sizes, train_scores, test_scores = learning_curve(\n    model, X_sample, y_sample, cv=3, scoring=\"r2\",\n    train_sizes=np.linspace(0.1, 1.0, 5)\n)\n\nplt.figure()\nplt.plot(train_sizes, train_scores.mean(axis=1), marker=\"o\", label=\"Entrenamiento\")\nplt.plot(train_sizes, test_scores.mean(axis=1), marker=\"o\", label=\"Validación CV\")\nplt.xlabel(\"Tamaño de entrenamiento (muestra)\")\nplt.ylabel(\"R² promedio (CV)\")\nplt.title(\"Curva de aprendizaje (muestra)\")\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Midterm",
    "section": "",
    "text": "import pandas as pd\ndf = pd.read_csv(\"data/1.-mpceip_deeco_exportaciones_eeuu_2024_01.csv\", encoding=\"latin1\")\ndf.head()\n\n\n\n\n\n\n\n\nAño\nMes\nPaís Destino\nCapítulo\nProd Principal N4.PP N4 BCE (Descrip)\n6D\n8D\nTRADICIONAL Y NO TRAD\nNo Petrolero Y PETRO\nCódigo Subpartida\nSuma de FOB (miles)\nSuma de TM (Peso Neto)\n\n\n\n\n0\n2024\n1\nESTADOS UNIDOS\n1\nAnimales Vivos No Para Alimentación\n10129\n1012990\nNO TRADICIONAL\nNo Petrolero\n101299000\n3.0000\n0.58000\n\n\n1\n2024\n1\nESTADOS UNIDOS\n1\nAnimales Vivos No Para Alimentación\n10620\n1062000\nNO TRADICIONAL\nNo Petrolero\n106200000\n200.0000\n22.50000\n\n\n2\n2024\n1\nESTADOS UNIDOS\n2\nCarne_ Leche Y Elaborados\n20890\n2089000\nNO TRADICIONAL\nNo Petrolero\n208900000\n31.0580\n22.90720\n\n\n3\n2024\n1\nESTADOS UNIDOS\n3\nAnimales Vivos No Para Alimentación\n30119\n3011900\nNO TRADICIONAL\nNo Petrolero\n301190000\n4.6980\n0.08000\n\n\n4\n2024\n1\nESTADOS UNIDOS\n3\nAnimales Vivos No Para Alimentación\n30199\n3019919\nNO TRADICIONAL\nNo Petrolero\n301991990\n148.3564\n12.16398"
  },
  {
    "objectID": "index.html#importar-el-dataset",
    "href": "index.html#importar-el-dataset",
    "title": "Midterm",
    "section": "",
    "text": "import pandas as pd\ndf = pd.read_csv(\"data/1.-mpceip_deeco_exportaciones_eeuu_2024_01.csv\", encoding=\"latin1\")\ndf.head()\n\n\n\n\n\n\n\n\nAño\nMes\nPaís Destino\nCapítulo\nProd Principal N4.PP N4 BCE (Descrip)\n6D\n8D\nTRADICIONAL Y NO TRAD\nNo Petrolero Y PETRO\nCódigo Subpartida\nSuma de FOB (miles)\nSuma de TM (Peso Neto)\n\n\n\n\n0\n2024\n1\nESTADOS UNIDOS\n1\nAnimales Vivos No Para Alimentación\n10129\n1012990\nNO TRADICIONAL\nNo Petrolero\n101299000\n3.0000\n0.58000\n\n\n1\n2024\n1\nESTADOS UNIDOS\n1\nAnimales Vivos No Para Alimentación\n10620\n1062000\nNO TRADICIONAL\nNo Petrolero\n106200000\n200.0000\n22.50000\n\n\n2\n2024\n1\nESTADOS UNIDOS\n2\nCarne_ Leche Y Elaborados\n20890\n2089000\nNO TRADICIONAL\nNo Petrolero\n208900000\n31.0580\n22.90720\n\n\n3\n2024\n1\nESTADOS UNIDOS\n3\nAnimales Vivos No Para Alimentación\n30119\n3011900\nNO TRADICIONAL\nNo Petrolero\n301190000\n4.6980\n0.08000\n\n\n4\n2024\n1\nESTADOS UNIDOS\n3\nAnimales Vivos No Para Alimentación\n30199\n3019919\nNO TRADICIONAL\nNo Petrolero\n301991990\n148.3564\n12.16398"
  }
]